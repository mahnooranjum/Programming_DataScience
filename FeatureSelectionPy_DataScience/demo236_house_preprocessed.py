# -*- coding: utf-8 -*-
"""Demo236_House_Preprocessed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D-6jwkEPkq3S7AiHnSH2SYp6FJPGArlF
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from itertools import product

"""## Get  Dataset"""

def get_regression(X, y, regressors,texts):
  

  f, axarr = plt.subplots(2,2, sharex='col', sharey='row', figsize=(10, 8))

  for idx, clf, tt in zip(product([0, 1], [0, 1]),
                          regressors,
                          texts):
      y_pred = clf.predict(np.sort(X_test.reshape(-1)).reshape(-1,1))

      axarr[idx[0], idx[1]].plot(np.sort(X_test.reshape(-1)).reshape(-1,1), y_pred)
      axarr[idx[0], idx[1]].scatter(X, y, c=y,
                                    s=20, edgecolor='k')
      axarr[idx[0], idx[1]].set_title(tt)

  plt.show()

def report_regression( X, y,regressors,texts):
  from sklearn.metrics import mean_squared_error as mse
  results = {}
  for clf, tt in zip(     regressors,
                          texts):
      y_pred = clf.predict(X)
      results[tt] = mse(y, y_pred)


  return results

from google.colab import drive
drive.mount("/content/gdrive")

data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/FeatureSelection/train_house.csv')

data.keys()

y = data.SalePrice
X = data.drop(columns=['SalePrice'])

X.dtypes

X['SaleCondition'].dtype

objs = []
nums = []
for i in X.columns:
  if X[i].dtype == 'O':
    objs.append(i)
  else:
    nums.append(i)

na_objs = []
na_nums = []
for i in X.columns:
  if (X[i].isnull().sum() > 0):
    print(i, " ", X[i].isnull().sum())
    if X[i].dtype == 'O':
      na_objs.append(i)
    else:
      na_nums.append(i)

na_nums

na_objs

def impute(df, columns, dft):
    df_temp = df.copy()
    for column in columns:
      df_temp[column] = df_temp[column].apply(lambda x: np.random.choice(dft[column].dropna().values) if pd.isnull(x) else x)
    return df_temp

X = impute(X,na_nums + na_objs , X)

X.isnull().sum()

X.head()

for col in objs:
  mapper = {k:i for i, k in enumerate(X[col].unique(), 0)} 
  X[col] = X[col].map(mapper)

X.head()

objs_oh = []
for col in objs:
  if len(X[col].unique())>2:
    objs_oh.append(col)

objs_oh

len(X.columns)

for i in objs_oh:
  X = pd.concat([X, pd.get_dummies(X[i], prefix = i, drop_first=True)], axis=1)

X = X.drop(columns=objs_oh)

len(X.columns)

# from sklearn.decomposition import PCA
# obj = PCA()
# X   = obj.fit_transform(X)

# TRAIN TEST SPLIT
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
regressors = [
    DecisionTreeRegressor().fit(X_train, y_train),
    KNeighborsRegressor().fit(X_train, y_train),
    SVR(gamma=.1, kernel='rbf').fit(X_train, y_train),
    RandomForestRegressor().fit(X_train, y_train)
    ]
texts = [    "DecisionTreeRegressor",
              "KNeighborsRegressor",
              "SVR",
              "RandomForestRegressor"]

# get_regression(X_test, y_test, regressors, texts)

report = report_regression( X_test, y_test,regressors,texts)
report

keys = list(report.keys())
vals = [float(report[k]) for k in keys]
sns.barplot(x=keys, y=vals)

