# -*- coding: utf-8 -*-
"""Demo211_Selection_XGBoost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ye8OljKevjxigTwcClsO6_7jXRdqgmoE

# **Survival of the FITtest**
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
!sudo pip install xgboost

# Visualising the results
def plot_model(classifier, X_set, y_set, y_test, y_pred, text):
  from sklearn.metrics import accuracy_score
  print("===== Accuracy Score =====")
  print(accuracy_score(y_test, y_pred))

  from sklearn.metrics import classification_report
  print("===== Accuracy Score =====")
  class_report = classification_report(y_test, y_pred)
  print(class_report)
  
  from matplotlib.colors import ListedColormap
  X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                    np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
  plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
            alpha = 0.75, cmap = ListedColormap(('pink', 'cyan')))
  plt.xlim(X1.min(), X1.max())
  plt.ylim(X2.min(), X2.max())
  for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'blue'))(i), label = j)
  plt.title(text)
  plt.xlabel('X')
  plt.ylabel('y')
  plt.legend()
  plt.show()

"""## Get Breast Cancer Dataset"""

from sklearn.datasets import load_breast_cancer
data = load_breast_cancer()

data.keys()

X = data.data
y = data.target

# TRAIN TEST SPLIT
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

import xgboost
from xgboost import XGBClassifier
# define the model
model = XGBClassifier()
model.fit(X_train, y_train)
importance = model.feature_importances_
# summarize importance
# for i,v in enumerate(importance):
# 	print('Feature: %0d, Score: %.5f' % (i,v))
# plot importance
fig, ax = plt.subplots(figsize=(10,8))
sns.set_theme(style="whitegrid", palette="pastel")
g = sns.barplot([x for x in range(len(importance))], importance, ax=ax)
g.set_xticklabels([])
sns.set_style("whitegrid")
g.set_title("Feature Importance XGboost")

type(importance)

n = 5
indices = (-importance).argsort()[:n]
print(indices)

y_pred = model.predict(X_test)
y_pred = y_pred < 0.5

X_train.shape

from sklearn.metrics import accuracy_score
acc_score = accuracy_score(y_test, y_pred)
print(X_train.shape, acc_score)

classifier = XGBClassifier()
classifier.fit(X_train[:, indices], y_train)
y_pred = classifier.predict(X_test[:, indices])
acc_score = accuracy_score(y_test, y_pred)
print(X_train[:, indices].shape, acc_score)

